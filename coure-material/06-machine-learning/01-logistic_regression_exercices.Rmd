---
title: "ML Algorithms for classification"
subtitle: "Exercises and solutions Logistic regression"
venue: "GL R courses"
author: "Hicham Zmarrou"
date: "Notebook -- <http://bit.ly/2q9NPSU>  <br /> <br />"
output:
  html_notebook:
    highlight: pygments
    theme: cosmo
    toc: true
    toc_float: true
    number_sections: FALSE
---


<hr>

[Visit my website](http://trefoil.ml/) for more like this!

__References__

Most of this material is borrowed from:

* Textbook: [Introduction to statistical learning](http://www-bcf.usc.edu/~gareth/ISL/)

____________________________________

In the presentation , we used logisitc regression to predict the probability of "default" using "balance" on the "Default" data set. 
We will now extend this model to account the `income` variable and estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis.   

Fit a logistic regression model that uses "income" and "balance" to predict "default".

```{r}
library(ISLR)
attach(Default)
set.seed(1)
fit.glm      <- glm(default ~ ...., data = Default, family = "binomial")
summary(...)

```

* Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:

  - Split the sample set into a training set and a validation set.

```{r}
set.seed(1)
idx_train <- sample(dim(Default)[1], dim(Default)[1]/2)
train     <- Default[...,]
```
 - Fit a multiple logistic regression model using only the training observations.

```{r}
fit.glm <- glm(default ~ ..., data = train, family = "binomial")
summary(...)
```

- Obtain a prediction of default status for each individual in the validation (test) set by computing the posterior probability of default for that individual, and classifying the individual to the "default" category if the posterior probability is greater than 0.5.

```{r}

probs <- predict(..., newdata = Default[..., ], type = "response")
pred.glm <- rep("No", length(probs))
pred.glm[probs > 0.5] <- "Yes"

```

 - Compute the validation set error, which is the fraction of the observations in the validation     set that are misclassified.
```{r}
mean(pred.glm != Default[..., ]$default)
```
We have a $2.86$% test error rate with the validation set approach.

* Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained.

```{r}
set.seed(1)
idx_train <- sample(dim(Default)[1], dim(Default)[1] / 2)
fit.glm <- glm(default ~ income + balance, data = Default, family = "binomial", subset = ...)
probs <- predict(fit.glm, newdata = Default[..., ], type = "response")
pred.glm <- rep("No", length(probs))
pred.glm[probs > 0.5] <- "Yes"
mean(pred.glm != Default[..., ]$default)
```



```{r}
set.seed(...)
idx_train <- sample(dim(Default)[1], dim(Default)[1] / 2)
fit.glm <- glm(default ~ income + balance, data = Default, family = "binomial", subset = ...)
probs <- predict(fit.glm, newdata = Default[..., ], type = "response")
pred.glm <- rep("No", length(probs))
pred.glm[probs > 0.5] <- "Yes"
mean(pred.glm != Default[..., ]$default)
```

```{r}
set.seed(...)
idx_train <- sample(dim(Default)[1], dim(Default)[1] / 2)
fit.glm <- glm(default ~ income + balance, data = Default, family = "binomial", subset = ...)
probs <- predict(fit.glm, newdata = Default[..., ], type = "response")
pred.glm <- rep("No", length(probs))
pred.glm[probs > 0.5] <- "Yes"
mean(pred.glm != Default[..., ]$default)
```

We see that the validation estimate of the test error rate can be variable, depending on precisely which observations are included in the training set and which observations are included in the validation set.

* Now consider a logistic regression model that predicts the probability of "default" using "income", "balance", and the dummy variable for "student". Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for "student" leads to a reduction in the test error rate.

```{r}
idx_train <- sample(dim(Default)[1], dim(Default)[1] / 2)
fit.glm <- glm(default ~ ..., data = Default, family = "binomial", subset = idx_train)
pred.glm <- rep("No", length(probs))
probs <- predict(fit.glm, newdata = Default[-idx_train, ], type = "response")
pred.glm[probs > 0.5] <- "Yes"
mean(pred.glm != Default[-idx_train, ]$default)
```

* Compute the Accuracy , Misclassification rate, True positive rate, False Positive Rate, Specificity,  False Positive Rate, Precision for the fitted model.
(Hint use the confusionMatrix() function from the caret package.) 

